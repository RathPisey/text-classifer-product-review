{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read positive and negative words from text files\n",
    "with open('positive-words.txt', 'r') as f:\n",
    "    positive_words = f.read().splitlines()\n",
    "\n",
    "with open('negative-words.txt', 'r') as f:\n",
    "    negative_words = f.read().splitlines()\n",
    "\n",
    "# print(negative_words)\n",
    "# list of pronouns\n",
    "pronouns = ['I', 'me', 'my', 'you', 'your']\n",
    "\n",
    "# function to extract features\n",
    "def extract_features(review, label):\n",
    "#     print(\"Start Extract\")\n",
    "#     print(review)\n",
    "#     review = review[0]\n",
    "    review = review.lower()\n",
    "    # tokenize the review text\n",
    "#     print(type(review))\n",
    "#     print(review)\n",
    "    tokens = word_tokenize(review)\n",
    "    # remove punctuation\n",
    "#     review = re.sub(r'[^\\w\\s]', '', review)\n",
    "#     print(review)\n",
    "\n",
    "#     # remove stop words\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # lemmatize tokens\n",
    "#     lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # count of positive words\n",
    "    pos_count = 0\n",
    "    for word in positive_words:\n",
    "        pos_count += lemmatized_tokens.count(word)\n",
    "\n",
    "    # count of negative words\n",
    "    neg_count = 0\n",
    "    for word in negative_words:\n",
    "        neg_count += lemmatized_tokens.count(word)\n",
    "\n",
    "    # presence of 'no'\n",
    "    no_count = 1 if 'no' in lemmatized_tokens else 0\n",
    "    \n",
    "    # presence of 'not'\n",
    "    not_count = 1 if 'not' in lemmatized_tokens else 0\n",
    "    \n",
    "    # count of pronouns\n",
    "    pron_count = 0\n",
    "    for word in pronouns:\n",
    "        pron_count += lemmatized_tokens.count(word)\n",
    "\n",
    "    # presence of '!'\n",
    "    excl_count = 1 if '!' in review else 0\n",
    "\n",
    "    # log(length of review)\n",
    "    log_length = np.log(len(lemmatized_tokens)+1)\n",
    "\n",
    "    return [pos_count, neg_count, no_count, not_count, pron_count, excl_count, log_length]\n",
    "#     return [pos_count, neg_count, no_count, pron_count, excl_count, log_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22936\n",
      "22932\n",
      "45868\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "# positive_reviews = []\n",
    "# with open('positive-reviews.txt', 'r') as f:\n",
    "#     for line in f:\n",
    "#         positive_reviews.append(line.strip())\n",
    "\n",
    "# negative_reviews = []\n",
    "# with open('negative-reviews.txt', 'r') as f:\n",
    "#     for line in f:\n",
    "#         negative_reviews.append(line.strip())\n",
    "\n",
    "# # extract features for each review\n",
    "# # positive_reviews = []\n",
    "# for review in positive_reviews:\n",
    "# #     print(type(review))\n",
    "#     features = extract_features(review)\n",
    "#     positive_reviews.append((features, 'positive'))\n",
    "\n",
    "# # negative_reviews = []\n",
    "# for review in negative_reviews:\n",
    "#     features = extract_features(review)\n",
    "#     negative_reviews.append((features, 'negative'))\n",
    "\n",
    "reviews = []\n",
    "with open('positive-reviews.txt', 'r') as pos_file, open('negative-reviews.txt', 'r') as neg_file:\n",
    "    pos_reviews = pos_file.readlines()\n",
    "    neg_reviews = neg_file.readlines()\n",
    "    for review, label in zip(pos_reviews, ['positive']*len(pos_reviews)):\n",
    "        reviews.append((review, label))\n",
    "    for review, label in zip(neg_reviews, ['negative']*len(neg_reviews)):\n",
    "        reviews.append((review, label))\n",
    "\n",
    "\n",
    "# print(reviews[0:10])\n",
    "print(len(pos_reviews))\n",
    "print(len(neg_reviews))\n",
    "print(len(reviews))\n",
    "# train the classifier\n",
    "# classifier = NaiveBayesClassifier.train(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Very slow to warm up. Slow to initialize prior to printing. Noisy printer\\n', 'negative')\n",
      "Very slow to warm up. Slow to initialize prior to printing. Noisy printer\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 3, 0, 0, 0, 0, 2.772588722239781]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testre = reviews[24000]\n",
    "print(testre)\n",
    "print(testre[0])\n",
    "extract_features(testre[0],testre[1])\n",
    "\n",
    "# for i in reviews:\n",
    "#     for j in i[0]:\n",
    "#         if j == \"null\":\n",
    "#             print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0.6931471805599453], [2, 0, 0, 0, 0, 0, 2.3978952727983707], [1, 0, 0, 0, 0, 0, 1.0986122886681098], [0, 0, 0, 0, 0, 0, 2.1972245773362196], [4, 0, 0, 0, 0, 0, 2.6390573296152584], [1, 0, 0, 0, 0, 0, 1.6094379124341003], [1, 0, 0, 0, 0, 0, 2.302585092994046], [0, 0, 0, 0, 0, 0, 2.302585092994046], [3, 0, 0, 0, 0, 0, 2.70805020110221], [1, 0, 0, 0, 0, 0, 1.9459101490553132]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract the features and labels\n",
    "X = [extract_features(review, label) for review, label in reviews]\n",
    "y = [label for review, label in reviews]\n",
    "print(X[10:20])\n",
    "import numpy as np\n",
    "\n",
    "# check for NaN values in the input data\n",
    "if np.isnan(X).any():\n",
    "    # find the indices of the NaN values\n",
    "    idx = np.where(np.isnan(X))\n",
    "    # remove the NaN values from the input data\n",
    "#     X = np.delete(X, idx, axis=0)\n",
    "#     y = np.delete(y, idx, axis=0)\n",
    "    print(idx)\n",
    "\n",
    "# check for infinite values in the input data\n",
    "if np.isinf(X).any():\n",
    "    # find the indices of the infinite values\n",
    "    idx = np.where(np.isinf(X))\n",
    "    print(idx)\n",
    "    # remove the infinite values from the input data\n",
    "    X = np.delete(X, idx, axis=0)\n",
    "    y = np.delete(y, idx, axis=0)\n",
    "# check if there's missing values\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in X:\n",
    "#     if i[2] > 0:\n",
    "#         print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.55%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create an instance of the classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.93      0.85      4607\n",
      "    positive       0.91      0.76      0.83      4567\n",
      "\n",
      "    accuracy                           0.84      9174\n",
      "   macro avg       0.85      0.84      0.84      9174\n",
      "weighted avg       0.85      0.84      0.84      9174\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.91      0.85      4607\n",
      "    positive       0.89      0.78      0.83      4567\n",
      "\n",
      "    accuracy                           0.84      9174\n",
      "   macro avg       0.85      0.84      0.84      9174\n",
      "weighted avg       0.85      0.84      0.84      9174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize the logistic regression model\n",
    "# log_reg = LogisticRegression(random_state=42)\n",
    "# # Train the model on the training data\n",
    "# log_reg.fit(X_train, y_train)\n",
    "# # Make predictions on the testing data\n",
    "# y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# # Evaluation for logistic regression\n",
    "# print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "# print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "# print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "# print(\"F1-score: \", f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# # Initialize the random forest model\n",
    "# rf = RandomForestClassifier(random_state=42)\n",
    "# # Train the model on the training data\n",
    "# rf.fit(X_train, y_train)\n",
    "# # Make predictions on the testing data\n",
    "# y_pred = rf.predict(X_test)\n",
    "\n",
    "# # Evaluation for Random Forest\n",
    "# print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "# print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "# print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "# print(\"F1-score: \", f1_score(y_test, y_pred))\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred1 = log_reg.predict(X_test)\n",
    "\n",
    "#Evaluate the model\n",
    "print(classification_report(y_test, y_pred1, target_names=['negative', 'positive']))\n",
    "\n",
    "# Create an instance of the random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred2 = rf.predict(X_test)\n",
    "\n",
    "#Evaluate the model\n",
    "print(classification_report(y_test, y_pred2, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.83893826        nan 0.84060065        nan 0.84090042]\n",
      "  warnings.warn(\n",
      "c:\\python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the train scores are non-finite: [       nan 0.83897913        nan 0.84055976        nan 0.84096855]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# specify the hyperparameters and their possible values\n",
    "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# create a logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# create a grid search object\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, return_train_score=True)\n",
    "\n",
    "# fit the grid search object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the best set of hyperparameters\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new logistic regression model with the best hyperparameters\n",
    "logreg = LogisticRegression(**grid_search.best_params_)\n",
    "\n",
    "# fit the model to the entire training set\n",
    "logreg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.93      0.85      4607\n",
      "    positive       0.91      0.76      0.83      4567\n",
      "\n",
      "    accuracy                           0.84      9174\n",
      "   macro avg       0.85      0.84      0.84      9174\n",
      "weighted avg       0.85      0.84      0.84      9174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set\n",
    "y_pred3 = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred3, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred3)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(log_reg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"classifier.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the product has no abnormal. It works great\"\n",
    "label = \"\"\n",
    "features = extract_features(sentence, label)\n",
    "label = loaded_model.predict([features])\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
